{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e1a10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn nltk transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91d8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f8e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/logan.ramos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd67da-808f-4d78-900c-d94d1d4b226a",
   "metadata": {},
   "source": [
    "## Synthetic Data (NOTE: pending professor approval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fa579c-0e3d-4a25-8ef8-af90a0a002e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 completed.\n",
      "Epoch 2/3 completed.\n",
      "Epoch 3/3 completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Positive examples (labeled as 1)\n",
    "synthetic_non_examples = [\n",
    "    \"I love the weather today, it's so sunny!\",\n",
    "    \"This new phone is amazing, it has so many cool features.\",\n",
    "    \"The book was an absolute masterpiece, I couldn’t put it down.\",\n",
    "    \"I finally got the promotion I’ve been working so hard for!\",\n",
    "    \"The new software update really improved my laptop's performance.\",\n",
    "    \"I feel really happy with the decision I made to move.\",\n",
    "    \"The park is such a peaceful place to walk and relax.\",\n",
    "    \"I just received a beautiful gift from a friend!\",\n",
    "    \"This recipe turned out fantastic, I will definitely make it again!\",\n",
    "    \"The vacation was incredible, I had the best time.\",\n",
    "    \"I finally fixed my car after days of trouble, such a relief!\",\n",
    "    \"This new workout routine has made me feel much stronger.\",\n",
    "    \"My friend and I had an amazing time at the concert last night.\"\n",
    "]\n",
    "\n",
    "# Negative examples (labeled as 0)\n",
    "synthetic_examples = [\n",
    "    \"The movie was so boring, I fell asleep halfway through.\",\n",
    "    \"I can't believe how bad the service was at that restaurant.\",\n",
    "    \"This is the worst concert I’ve ever attended.\",\n",
    "    \"The game was a huge disappointment, it wasn’t fun at all.\",\n",
    "    \"The news was so depressing, I couldn’t watch it anymore.\",\n",
    "    \"I’m really angry that I missed the meeting.\",\n",
    "    \"I can’t believe how terrible the traffic was today.\",\n",
    "    \"I had the worst customer service experience today.\",\n",
    "    \"I was so disappointed by the product’s quality.\",\n",
    "    \"I don't think I'll ever go back to that store again.\",\n",
    "    \"I’m so frustrated with how slow the internet is.\",\n",
    "    \"I regret buying that gadget, it was a waste of money.\"\n",
    "]\n",
    "\n",
    "positive_labels = [1] * len(synthetic_examples)\n",
    "negative_labels = [0] * len(synthetic_non_examples)\n",
    "labels = [*positive_labels, *negative_labels]\n",
    "texts = [*synthetic_examples, *synthetic_non_examples]\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def encode_texts(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    return tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "train_encodings = encode_texts(X_train)\n",
    "test_encodings = encode_texts(X_test)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_labels = torch.tensor(y_test)\n",
    "train_dataset = TensorDataset(train_encodings.input_ids, train_encodings.attention_mask, train_labels)\n",
    "test_dataset = TensorDataset(test_encodings.input_ids, test_encodings.attention_mask, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "model.train()\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} completed.\")\n",
    "model.save_pretrained(\"straw_man_model\")\n",
    "tokenizer.save_pretrained(\"straw_man_model\")\n",
    "\n",
    "def predict_straw_man(text):\n",
    "    encoding = encode_texts([text])\n",
    "    input_ids = encoding.input_ids\n",
    "    attention_mask = encoding.attention_mask\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"Strawman\" if prediction == 1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb821b31-1977-4cfd-983c-32173f5ea044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vance: For four years, the United States of America, we had a president who stood up at press conferences and talked tough about Vladimir Putin, and then Putin invaded Ukraine and destroyed a significant chunk of the country. The path to peace and the path to prosperity is, maybe, engaging in diplomacy. We tried the pathway of Joe Biden, of thumping our chest and pretending that the president of the United States' words mattered more than the president of the United States' actions. What makes America a good country is America engaging in diplomacy. That's what President Trump is doing.\n",
      "Strawman detected\n",
      "-------\n",
      "\n",
      "Zelenskyy: Can I ask you?\n",
      "Ad Hominem detected\n",
      "-------\n",
      "\n",
      "Vance: Sure. Yeah.\n",
      "nice!\n",
      "-------\n",
      "\n",
      "Zelenskyy: OK. So he (Putin) occupied it, our parts, big parts of Ukraine, parts of east and Crimea. So he occupied it in 2014. So during a lot of years — I’m not speaking about just Biden, but those times was (Barack) Obama, then President Obama, then President Trump, then President Biden, now President Trump. And God bless, now, President Trump will stop him. But during 2014, nobody stopped him. He just occupied and took. He killed people. You know what the --\n",
      "Strawman detected\n",
      "Ad Hominem detected\n",
      "-------\n",
      "\n",
      "Trump: 2015?\n",
      "Strawman detected\n",
      "-------\n",
      "\n",
      "Zelenskyy: 2014.\n",
      "Ad Hominem detected\n",
      "-------\n",
      "\n",
      "Trump: Oh, 2014? I was not here.\n",
      "Strawman detected\n",
      "-------\n",
      "\n",
      "Vance: That’s exactly right.\n",
      "nice!\n",
      "-------\n",
      "\n",
      "Zelenskyy: Yes, but during 2014 ‘til 2022, the situation is the same, that people have been dying on the contact line. Nobody stopped him. You know that we had conversations with him, a lot of conversations, my bilateral conversation. And we signed with him, me, like, you, president, in 2019, I signed with him the deal. I signed with him, (French President Emmanuel) Macron and (former German Chancellor Angela) Merkel. We signed ceasefire. Ceasefire. All of them told me that he will never go … But after that, he broke the ceasefire, he killed our people, and he didn’t exchange prisoners. We signed the exchange of prisoners. But he didn’t do it. What kind of diplomacy, JD, you are speaking about? What do you mean?\n",
      "Ad Hominem detected\n",
      "-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trump_zelensky = [\n",
    "    \"Vance: For four years, the United States of America, we had a president who stood up at press conferences and talked tough about Vladimir Putin, and then Putin invaded Ukraine and destroyed a significant chunk of the country. The path to peace and the path to prosperity is, maybe, engaging in diplomacy. We tried the pathway of Joe Biden, of thumping our chest and pretending that the president of the United States' words mattered more than the president of the United States' actions. What makes America a good country is America engaging in diplomacy. That's what President Trump is doing.\",\n",
    "    \"Zelenskyy: Can I ask you?\",\n",
    "    \"Vance: Sure. Yeah.\",\n",
    "    \"Zelenskyy: OK. So he (Putin) occupied it, our parts, big parts of Ukraine, parts of east and Crimea. So he occupied it in 2014. So during a lot of years — I’m not speaking about just Biden, but those times was (Barack) Obama, then President Obama, then President Trump, then President Biden, now President Trump. And God bless, now, President Trump will stop him. But during 2014, nobody stopped him. He just occupied and took. He killed people. You know what the --\",\n",
    "    \"Trump: 2015?\",\n",
    "    \"Zelenskyy: 2014.\",\n",
    "    \"Trump: Oh, 2014? I was not here.\",\n",
    "    \"Vance: That’s exactly right.\",\n",
    "    \"Zelenskyy: Yes, but during 2014 ‘til 2022, the situation is the same, that people have been dying on the contact line. Nobody stopped him. You know that we had conversations with him, a lot of conversations, my bilateral conversation. And we signed with him, me, like, you, president, in 2019, I signed with him the deal. I signed with him, (French President Emmanuel) Macron and (former German Chancellor Angela) Merkel. We signed ceasefire. Ceasefire. All of them told me that he will never go … But after that, he broke the ceasefire, he killed our people, and he didn’t exchange prisoners. We signed the exchange of prisoners. But he didn’t do it. What kind of diplomacy, JD, you are speaking about? What do you mean?\"\n",
    "]\n",
    "\n",
    "# Dummy predictions for demonstration (replace with actual prediction function calls)\n",
    "def predict_straw_man(s):\n",
    "    return 'Strawman detected' if 'Trump' in s else None\n",
    "\n",
    "def predict_ad_hominem(s):\n",
    "    return 'Ad Hominem detected' if 'Zelenskyy' in s else None\n",
    "\n",
    "for s in trump_zelensky:\n",
    "    print(s)\n",
    "    a = predict_straw_man(s)\n",
    "    b = predict_ad_hominem(s)\n",
    "    \n",
    "    if a:\n",
    "        print(a)\n",
    "    if b:\n",
    "        print(b)\n",
    "    elif not a:\n",
    "        print(\"nice!\")\n",
    "\n",
    "    print(f\"-------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78684a67-8163-43d1-a163-5523dd326c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246f1d7-7f4e-47cd-8ba8-534150dcf71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fd015-4f4a-4472-8f5a-a136d0edf637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
