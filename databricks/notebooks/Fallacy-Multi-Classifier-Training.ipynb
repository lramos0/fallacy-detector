{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ad39f7-cda9-4316-b15a-16deff140016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Dependencies and prep env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8244eae2-67ba-49d4-97ab-60e630033785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (2.22.0)\nRequirement already satisfied: transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (4.51.3)\nRequirement already satisfied: torch in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: nltk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (3.9.1)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.10.0)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (2.0.40)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (23.0.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.7.0)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.23.5)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (3.1.0)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.5.3)\nRequirement already satisfied: mlflow-skinny==2.22.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (2.22.0)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow) (3.8)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\nRequirement already satisfied: fastapi<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (1.32.1)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.20.0)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (1.32.1)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (5.3.2)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (4.25.5)\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\nRequirement already satisfied: packaging<25 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (23.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (2.28.1)\nRequirement already satisfied: cloudpickle<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\nRequirement already satisfied: uvicorn<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from transformers) (0.5.3)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from transformers) (2024.11.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from transformers) (0.30.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers) (3.16.1)\nRequirement already satisfied: tqdm>=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (3.4.2)\nRequirement already satisfied: triton==3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (3.3.0)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (9.5.1.17)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (2.26.2)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (1.11.1.6)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (12.6.4.1)\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (0.6.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (10.3.7.77)\nRequirement already satisfied: sympy>=1.13.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from torch) (1.14.0)\nRequirement already satisfied: setuptools>=40.8.0 in /databricks/python3/lib/python3.10/site-packages (from triton==3.3.0->torch) (65.5.1)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.14)\nRequirement already satisfied: itsdangerous>=2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: Werkzeug>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.10/site-packages (from graphene<4->mlflow) (2.8.2)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.0.5)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<3->mlflow) (2022.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2.0.4)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.28.1)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\nRequirement already satisfied: deprecated>=1.2.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.53b1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: h11>=0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.3.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.2.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.2.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.5.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow transformers torch scikit-learn nltk\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854e8f12-8639-41fe-a3bb-a39b7438253b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70633d38-b7df-4579-afd1-2c2d7d8d97f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unified Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da4051b9-aee9-400c-aa20-672181855d94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /home/spark-b1faa9a0-ee82-4d76-938f-b6/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red_herring] examples: 36\n[red_herring] non-examples: 38\n[straw_man] examples: 1\n[straw_man] non-examples: 7\n[slippery_slope] examples: 1\n[slippery_slope] non-examples: 7\n[attacking] examples: 0\n[attacking] non-examples: 0\n[ad_hominem] examples: 28\n[ad_hominem] non-examples: 60\n[hasty_generalization] examples: 0\n[hasty_generalization] non-examples: 0\n[ignorance] examples: 42\n[ignorance] non-examples: 37\n[hypocrisy] examples: 22\n[hypocrisy] non-examples: 43\n[stacking_deck] examples: 16\n[stacking_deck] non-examples: 15\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def load_fallacy_data(fallacy_name: str):\n",
    "    # Query using Spark SQL\n",
    "    examples_df = spark.sql(f\"\"\"\n",
    "        SELECT text \n",
    "        FROM logical_fallacy_data.{fallacy_name}\n",
    "        WHERE label = true\n",
    "    \"\"\")\n",
    "\n",
    "    non_examples_df = spark.sql(f\"\"\"\n",
    "        SELECT text \n",
    "        FROM logical_fallacy_data.{fallacy_name}\n",
    "        WHERE label = false\n",
    "    \"\"\")\n",
    "\n",
    "    # Convert to Pandas (safe in Databricks serverless)\n",
    "    examples = examples_df.toPandas()['text'].tolist()\n",
    "    non_examples = non_examples_df.toPandas()['text'].tolist()\n",
    "\n",
    "    print(f\"[{fallacy_name}] examples: {len(examples)}\")\n",
    "    print(f\"[{fallacy_name}] non-examples: {len(non_examples)}\")\n",
    "\n",
    "    return examples, non_examples\n",
    "\n",
    "fallacies = [\n",
    "    \"red_herring\",\n",
    "    \"straw_man\",\n",
    "    \"slippery_slope\",\n",
    "    \"attacking\",\n",
    "    \"ad_hominem\",\n",
    "    \"hasty_generalization\",\n",
    "    \"ignorance\",\n",
    "    \"hypocrisy\",\n",
    "    \"stacking_deck\"\n",
    "]\n",
    "\n",
    "fallacy_data = {}\n",
    "\n",
    "for name in fallacies:\n",
    "    examples, non_examples = load_fallacy_data(name)\n",
    "    fallacy_data[name] = {\n",
    "        \"examples\": examples,\n",
    "        \"non_examples\": non_examples\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4be71ef5-4ddc-4718-967e-88a78ddeeb15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unified Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee6334f-ee8d-4b70-82c5-4fce39ce6cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "def train_fallacy_model(fallacy_name, examples, non_examples, output_dir=\"models\", epochs=3, batch_size=8, lr=2e-5):\n",
    "    if not examples or not non_examples:\n",
    "        print(f\"⚠️ Skipping {fallacy_name}: empty examples or non-examples.\")\n",
    "        return\n",
    "    # Prepare training data\n",
    "    texts = examples + non_examples\n",
    "    labels = [1] * len(examples) + [0] * len(non_examples)\n",
    "\n",
    "    # Load tokenizer and encode\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
    "    inputs = encodings['input_ids']\n",
    "    masks = encodings['attention_mask']\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    # Build dataset and split\n",
    "    dataset = TensorDataset(inputs, masks, labels_tensor)\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    # Load model\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch in train_loader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.tolist())\n",
    "            true_labels.extend(b_labels.tolist())\n",
    "\n",
    "    print(f\"\\n[Evaluation for {fallacy_name}]\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "\n",
    "    # Save model/tokenizer\n",
    "    model_dir = os.path.join(output_dir, fallacy_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "    print(f\"✅ Model saved to {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f748f2-f243-41e7-9ad7-2f896298a048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load fallacy data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182cfafa-53ce-4ddd-9e0e-e1f0d3274d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red_herring] examples: 36\n[red_herring] non-examples: 38\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for red_herring]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         5\n           1       1.00      1.00      1.00        10\n\n    accuracy                           1.00        15\n   macro avg       1.00      1.00      1.00        15\nweighted avg       1.00      1.00      1.00        15\n\n✅ Model saved to models/red_herring\n[straw_man] examples: 1\n[straw_man] non-examples: 7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for straw_man]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         2\n\n    accuracy                           1.00         2\n   macro avg       1.00      1.00      1.00         2\nweighted avg       1.00      1.00      1.00         2\n\n✅ Model saved to models/straw_man\n[slippery_slope] examples: 1\n[slippery_slope] non-examples: 7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for slippery_slope]\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       2.0\n           1       0.00      0.00      0.00       0.0\n\n    accuracy                           0.00       2.0\n   macro avg       0.00      0.00      0.00       2.0\nweighted avg       0.00      0.00      0.00       2.0\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/slippery_slope\n[attacking] examples: 0\n[attacking] non-examples: 0\n⚠️ Skipping attacking: empty examples or non-examples.\n❌ No data for: attacking\n[ad_hominem] examples: 28\n[ad_hominem] non-examples: 60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for ad_hominem]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        11\n           1       1.00      1.00      1.00         7\n\n    accuracy                           1.00        18\n   macro avg       1.00      1.00      1.00        18\nweighted avg       1.00      1.00      1.00        18\n\n✅ Model saved to models/ad_hominem\n[hasty_generalization] examples: 0\n[hasty_generalization] non-examples: 0\n⚠️ Skipping hasty_generalization: empty examples or non-examples.\n❌ No data for: hasty_generalization\n[ignorance] examples: 42\n[ignorance] non-examples: 37\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for ignorance]\n              precision    recall  f1-score   support\n\n           0       0.83      1.00      0.91         5\n           1       1.00      0.91      0.95        11\n\n    accuracy                           0.94        16\n   macro avg       0.92      0.95      0.93        16\nweighted avg       0.95      0.94      0.94        16\n\n✅ Model saved to models/ignorance\n[hypocrisy] examples: 22\n[hypocrisy] non-examples: 43\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for hypocrisy]\n              precision    recall  f1-score   support\n\n           0       0.80      1.00      0.89         8\n           1       1.00      0.60      0.75         5\n\n    accuracy                           0.85        13\n   macro avg       0.90      0.80      0.82        13\nweighted avg       0.88      0.85      0.84        13\n\n✅ Model saved to models/hypocrisy\n[stacking_deck] examples: 16\n[stacking_deck] non-examples: 15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for stacking_deck]\n              precision    recall  f1-score   support\n\n           0       1.00      0.25      0.40         4\n           1       0.50      1.00      0.67         3\n\n    accuracy                           0.57         7\n   macro avg       0.75      0.62      0.53         7\nweighted avg       0.79      0.57      0.51         7\n\n✅ Model saved to models/stacking_deck\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "# Safe temporary local storage\n",
    "local_model_dir = \"/local_disk0/tmp/fallacy_models\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "fallacies = [\n",
    "    \"red_herring\",\n",
    "    \"straw_man\",\n",
    "    \"slippery_slope\",\n",
    "    \"attacking\",\n",
    "    \"ad_hominem\",\n",
    "    \"hasty_generalization\",\n",
    "    \"ignorance\",\n",
    "    \"hypocrisy\",\n",
    "    \"stacking_deck\"\n",
    "]\n",
    "\n",
    "for fallacy_name in fallacies:\n",
    "    examples, non_examples = load_fallacy_data(fallacy_name)\n",
    "    train_fallacy_model(fallacy_name, examples, non_examples)\n",
    "    if not examples or not non_examples:\n",
    "        print(f\"❌ No data for: {fallacy_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3f9816-0522-453c-81e4-499c53cd86a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Move raw inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8eb1ab-0b9d-48c1-b93a-fbd18c193ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for attacking does not exist at models/attacking\nModel for hasty_generalization does not exist at models/hasty_generalization\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Safe temporary local storage\n",
    "local_model_dir = \"/local_disk0/tmp/fallacy_models\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "# Copy only trained models into safe path\n",
    "for fallacy in fallacies:\n",
    "    src = f\"models/{fallacy}\"\n",
    "    dst = f\"{local_model_dir}/{fallacy}\"\n",
    "    if os.path.exists(src):\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Model for {fallacy} does not exist at {src}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "953b818e-4d6c-454f-ba31-f48757f610cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Serve via MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "731d0d40-ee5f-4ab0-ad57-6850cc8cc919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping hasty_generalization: model not found at /local_disk0/tmp/fallacy_models/hasty_generalization\nSkipping appeal_to_ignorance: model not found at /local_disk0/tmp/fallacy_models/appeal_to_ignorance\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f01cb3d79384b92b4ebf89f4969246f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "import os\n",
    "import shutil\n",
    "import mlflow.pyfunc\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "class FallacyEnsembleModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        self.fallacy_types = [\n",
    "            \"straw_man\", \"red_herring\", \"ad_hominem\",\n",
    "            \"hasty_generalization\", \"appeal_to_ignorance\",\n",
    "            \"hypocrisy\", \"stacking_deck\"\n",
    "        ]\n",
    "        self.model_dir = context.artifacts[\"model_dir\"]\n",
    "        self.fallacy_models = {}\n",
    "\n",
    "        for fallacy in self.fallacy_types:\n",
    "            model_path = os.path.join(self.model_dir, fallacy)\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"Skipping {fallacy}: model not found at {model_path}\")\n",
    "                continue\n",
    "            try:\n",
    "                model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "                tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "                model.eval()\n",
    "                self.fallacy_models[fallacy] = (tokenizer, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {fallacy}: {e}\")\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        texts = model_input[\"text\"].tolist()\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            fallacy_scores = []\n",
    "            for fallacy, (tokenizer, model) in self.fallacy_models.items():\n",
    "                inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "                    probs = torch.softmax(logits, dim=1)\n",
    "                    fallacy_prob = probs[0][1].item()\n",
    "                fallacy_scores.append((fallacy, fallacy_prob))\n",
    "            fallacy_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            results.append(fallacy_scores)\n",
    "        return results\n",
    "\n",
    "# Path to save the MLflow model\n",
    "save_path = \"/local_disk0/tmp/fallacy_ensemble_model_v1\"\n",
    "shutil.rmtree(save_path, ignore_errors=True)\n",
    "\n",
    "# Save the model using MLflow\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=save_path,\n",
    "    python_model=FallacyEnsembleModel(),     # Class instance\n",
    "    artifacts={\"model_dir\": \"/local_disk0/tmp/fallacy_models\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aaf29e5-63b6-4365-95a8-cb2763dd4f69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register model to unity catalog\n",
    "weird databricks specific thing with respect to mlflow model registries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91db98e1-563e-401c-b176-7a4770cec1cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'fallacy_ensemble_uc' already exists. Creating a new version of this model...\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "# Register it in Unity Catalog or default registry\n",
    "registered_model_name = \"fallacy_ensemble_uc\"\n",
    "model_artifact_path = f\"<valid_run_id>/artifacts/fallacy_ensemble_model_v1\"\n",
    "try:\n",
    "    mlflow.register_model(f\"runs:/{model_artifact_path}\", registered_model_name)\n",
    "except:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "740d9e1a-aca2-4bca-a5ee-7e813dd7f748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b34e5c-083c-470e-9bf7-8282db0e5d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping hasty_generalization: model not found at /local_disk0/tmp/fallacy_ensemble_model_v1/artifacts/fallacy_models/hasty_generalization\nSkipping appeal_to_ignorance: model not found at /local_disk0/tmp/fallacy_ensemble_model_v1/artifacts/fallacy_models/appeal_to_ignorance\n[[('ad_hominem', 0.9208627939224243), ('stacking_deck', 0.683536946773529), ('straw_man', 0.527265191078186), ('red_herring', 0.37025919556617737), ('hypocrisy', 0.1460869014263153)]]\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(save_path)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"text\": [\"You're just a student.\"]})\n",
    "predictions = model.predict(df)\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7930981280555425,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Fallacy-Multi-Classifier-Training",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}