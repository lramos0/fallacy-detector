{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8244eae2-67ba-49d4-97ab-60e630033785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n  Downloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 29.0/29.0 MB 55.3 MB/s eta 0:00:00\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.4/10.4 MB 108.3 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 865.2/865.2 MB 4.1 MB/s eta 0:00:00\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (1.1.1)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 117.8 MB/s eta 0:00:00\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.10.0)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.5.3)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.7.0)\nCollecting docker<8,>=4.0.0\n  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.8/147.8 kB 19.3 MB/s eta 0:00:00\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\nCollecting mlflow-skinny==2.22.0\n  Downloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 83.6 MB/s eta 0:00:00\nCollecting graphene<4\n  Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.9/114.9 kB 14.2 MB/s eta 0:00:00\nCollecting alembic!=1.10.0,<2\n  Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 231.9/231.9 kB 32.8 MB/s eta 0:00:00\nCollecting sqlalchemy<3,>=1.4.0\n  Downloading sqlalchemy-2.0.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 122.0 MB/s eta 0:00:00\nCollecting markdown<4,>=3.3\n  Downloading markdown-3.8-py3-none-any.whl (106 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.2/106.2 kB 15.2 MB/s eta 0:00:00\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.23.5)\nCollecting Flask<4\n  Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.0/103.0 kB 15.8 MB/s eta 0:00:00\nCollecting gunicorn<24\n  Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.0/85.0 kB 13.0 MB/s eta 0:00:00\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (4.4.0)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.6.4)\nCollecting fastapi<1\n  Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.2/95.2 kB 16.7 MB/s eta 0:00:00\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (8.0.4)\nCollecting gitpython<4,>=3.1.9\n  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.6/207.6 kB 28.3 MB/s eta 0:00:00\nCollecting cloudpickle<4\n  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\nCollecting opentelemetry-api<3,>=1.9.0\n  Downloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.3/65.3 kB 11.4 MB/s eta 0:00:00\nRequirement already satisfied: packaging<25 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (23.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (2.28.1)\nCollecting opentelemetry-sdk<3,>=1.9.0\n  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.0/119.0 kB 27.4 MB/s eta 0:00:00\nCollecting pyyaml<7,>=5.1\n  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 kB 76.0 MB/s eta 0:00:00\nCollecting uvicorn<1\n  Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.5/62.5 kB 8.8 MB/s eta 0:00:00\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (5.3.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (4.25.5)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.20.0)\nCollecting pydantic<3,>=1.10.8\n  Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 443.9/443.9 kB 60.9 MB/s eta 0:00:00\nCollecting sqlparse<1,>=0.4.0\n  Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.4/44.4 kB 6.1 MB/s eta 0:00:00\nCollecting tqdm>=4.27\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 13.7 MB/s eta 0:00:00\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers) (3.16.1)\nCollecting huggingface-hub<1.0,>=0.30.0\n  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 481.4/481.4 kB 50.2 MB/s eta 0:00:00\nCollecting tokenizers<0.22,>=0.21\n  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 112.0 MB/s eta 0:00:00\nCollecting safetensors>=0.4.3\n  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 471.6/471.6 kB 51.7 MB/s eta 0:00:00\nCollecting regex!=2019.12.17\n  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 63.9 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.5.1.17\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 571.0/571.0 MB 5.2 MB/s eta 0:00:00\nCollecting typing-extensions<5,>=4.0.0\n  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.8/45.8 kB 5.9 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.6.77\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.3/89.3 kB 15.5 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.6.80\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 133.5 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.3.0.4\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.2/200.2 MB 16.9 MB/s eta 0:00:00\nCollecting fsspec\n  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.4/194.4 kB 21.3 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.5.4.2\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.6/216.6 MB 17.0 MB/s eta 0:00:00\nCollecting nvidia-cusparselt-cu12==0.6.3\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.8/156.8 MB 23.7 MB/s eta 0:00:00\nCollecting sympy>=1.13.3\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 147.1 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 95.5 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.6.77\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.7/897.7 kB 87.2 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.26.2\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 201.3/201.3 MB 17.6 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.7.1.2\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.2/158.2 MB 24.8 MB/s eta 0:00:00\nCollecting triton==3.3.0\n  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.4/156.4 MB 15.4 MB/s eta 0:00:00\nCollecting networkx\n  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 107.7 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.6.4.1\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.1/393.1 MB 9.3 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.7.77\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 56.1 MB/s eta 0:00:00\nCollecting nvidia-cufile-cu12==1.11.1.6\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 99.3 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12==12.6.85\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 131.9 MB/s eta 0:00:00\nRequirement already satisfied: setuptools>=40.8.0 in /databricks/python3/lib/python3.10/site-packages (from triton==3.3.0->torch) (65.5.1)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\nCollecting Mako\n  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 16.1 MB/s eta 0:00:00\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.14)\nCollecting click<9,>=7.0\n  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.2/98.2 kB 18.7 MB/s eta 0:00:00\nCollecting itsdangerous>=2.2\n  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nCollecting blinker>=1.9\n  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nCollecting Werkzeug>=3.1\n  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 41.6 MB/s eta 0:00:00\nCollecting graphql-core<3.3,>=3.1\n  Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 203.4/203.4 kB 14.7 MB/s eta 0:00:00\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.10/site-packages (from graphene<4->mlflow) (2.8.2)\nCollecting graphql-relay<3.3,>=3.1\n  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.0.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<3->mlflow) (2022.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2.0.4)\nCollecting greenlet>=1\n  Downloading greenlet-3.2.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 580.6/580.6 kB 60.4 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 69.7 MB/s eta 0:00:00\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.28.1)\nCollecting starlette<0.47.0,>=0.40.0\n  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.0/72.0 kB 15.0 MB/s eta 0:00:00\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 16.9 MB/s eta 0:00:00\nCollecting deprecated>=1.2.6\n  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0\n  Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\nCollecting zipp>=3.20\n  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\nCollecting opentelemetry-semantic-conventions==0.53b1\n  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.4/188.4 kB 27.5 MB/s eta 0:00:00\nCollecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 59.5 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nCollecting h11>=0.8\n  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\nCollecting wrapt<2,>=1.10\n  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 8.7 MB/s eta 0:00:00\nCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9)\nCollecting anyio<5,>=3.6.2\n  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.9/100.9 kB 18.3 MB/s eta 0:00:00\nCollecting exceptiongroup>=1.0.2\n  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.2.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.5.1)\nInstalling collected packages: nvidia-cusparselt-cu12, mpmath, zipp, wrapt, Werkzeug, typing-extensions, triton, tqdm, sympy, sqlparse, smmap, safetensors, regex, pyyaml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, markdown, Mako, itsdangerous, h11, gunicorn, greenlet, graphql-core, fsspec, exceptiongroup, cloudpickle, click, blinker, annotated-types, uvicorn, typing-inspection, sqlalchemy, pydantic-core, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, importlib_metadata, huggingface-hub, graphql-relay, gitdb, Flask, docker, deprecated, anyio, tokenizers, starlette, pydantic, opentelemetry-api, nvidia-cusolver-cu12, graphene, gitpython, alembic, transformers, torch, opentelemetry-semantic-conventions, fastapi, opentelemetry-sdk, mlflow-skinny, mlflow\n  Attempting uninstall: zipp\n    Found existing installation: zipp 1.0.0\n    Not uninstalling zipp at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'zipp'. No files were found to uninstall.\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib-metadata 4.6.4\n    Not uninstalling importlib-metadata at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n  Attempting uninstall: anyio\n    Found existing installation: anyio 3.5.0\n    Not uninstalling anyio at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'anyio'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f\n    Can't uninstall 'pydantic'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.9.0 which is incompatible.\nSuccessfully installed Flask-3.1.0 Mako-1.3.10 Werkzeug-3.1.3 alembic-1.15.2 annotated-types-0.7.0 anyio-4.9.0 blinker-1.9.0 click-8.1.8 cloudpickle-3.1.1 deprecated-1.2.18 docker-7.1.0 exceptiongroup-1.2.2 fastapi-0.115.12 fsspec-2025.3.2 gitdb-4.0.12 gitpython-3.1.44 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.1 gunicorn-23.0.0 h11-0.16.0 huggingface-hub-0.30.2 importlib_metadata-8.6.1 itsdangerous-2.2.0 markdown-3.8 mlflow-2.22.0 mlflow-skinny-2.22.0 mpmath-1.3.0 networkx-3.4.2 nltk-3.9.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opentelemetry-api-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 pydantic-2.11.4 pydantic-core-2.33.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 smmap-5.0.2 sqlalchemy-2.0.40 sqlparse-0.5.3 starlette-0.46.2 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.51.3 triton-3.3.0 typing-extensions-4.13.2 typing-inspection-0.4.0 uvicorn-0.34.2 wrapt-1.17.2 zipp-3.21.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow transformers torch scikit-learn nltk\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854e8f12-8639-41fe-a3bb-a39b7438253b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70633d38-b7df-4579-afd1-2c2d7d8d97f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unified Fallacy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da4051b9-aee9-400c-aa20-672181855d94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /home/spark-b1faa9a0-ee82-4d76-938f-b6/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red_herring] examples: 36\n[red_herring] non-examples: 38\n[straw_man] examples: 1\n[straw_man] non-examples: 7\n[slippery_slope] examples: 1\n[slippery_slope] non-examples: 7\n[attacking] examples: 0\n[attacking] non-examples: 0\n[ad_hominem] examples: 28\n[ad_hominem] non-examples: 60\n[hasty_generalization] examples: 0\n[hasty_generalization] non-examples: 0\n[ignorance] examples: 42\n[ignorance] non-examples: 37\n[hypocrisy] examples: 22\n[hypocrisy] non-examples: 43\n[stacking_deck] examples: 16\n[stacking_deck] non-examples: 15\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def load_fallacy_data(fallacy_name: str):\n",
    "    # Query using Spark SQL\n",
    "    examples_df = spark.sql(f\"\"\"\n",
    "        SELECT text \n",
    "        FROM logical_fallacy_data.{fallacy_name}\n",
    "        WHERE label = true\n",
    "    \"\"\")\n",
    "\n",
    "    non_examples_df = spark.sql(f\"\"\"\n",
    "        SELECT text \n",
    "        FROM logical_fallacy_data.{fallacy_name}\n",
    "        WHERE label = false\n",
    "    \"\"\")\n",
    "\n",
    "    # Convert to Pandas (safe in Databricks serverless)\n",
    "    examples = examples_df.toPandas()['text'].tolist()\n",
    "    non_examples = non_examples_df.toPandas()['text'].tolist()\n",
    "\n",
    "    print(f\"[{fallacy_name}] examples: {len(examples)}\")\n",
    "    print(f\"[{fallacy_name}] non-examples: {len(non_examples)}\")\n",
    "\n",
    "    return examples, non_examples\n",
    "\n",
    "fallacies = [\n",
    "    \"red_herring\",\n",
    "    \"straw_man\",\n",
    "    \"slippery_slope\",\n",
    "    \"attacking\",\n",
    "    \"ad_hominem\",\n",
    "    \"hasty_generalization\",\n",
    "    \"ignorance\",\n",
    "    \"hypocrisy\",\n",
    "    \"stacking_deck\"\n",
    "]\n",
    "\n",
    "fallacy_data = {}\n",
    "\n",
    "for name in fallacies:\n",
    "    examples, non_examples = load_fallacy_data(name)\n",
    "    fallacy_data[name] = {\n",
    "        \"examples\": examples,\n",
    "        \"non_examples\": non_examples\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee6334f-ee8d-4b70-82c5-4fce39ce6cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "def train_fallacy_model(fallacy_name, examples, non_examples, output_dir=\"models\", epochs=3, batch_size=8, lr=2e-5):\n",
    "    if not examples or not non_examples:\n",
    "        print(f\"⚠️ Skipping {fallacy_name}: empty examples or non-examples.\")\n",
    "        return\n",
    "    # Prepare training data\n",
    "    texts = examples + non_examples\n",
    "    labels = [1] * len(examples) + [0] * len(non_examples)\n",
    "\n",
    "    # Load tokenizer and encode\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors='pt')\n",
    "    inputs = encodings['input_ids']\n",
    "    masks = encodings['attention_mask']\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    # Build dataset and split\n",
    "    dataset = TensorDataset(inputs, masks, labels_tensor)\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    # Load model\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch in train_loader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.tolist())\n",
    "            true_labels.extend(b_labels.tolist())\n",
    "\n",
    "    print(f\"\\n[Evaluation for {fallacy_name}]\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "\n",
    "    # Save model/tokenizer\n",
    "    model_dir = os.path.join(output_dir, fallacy_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "    print(f\"✅ Model saved to {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182cfafa-53ce-4ddd-9e0e-e1f0d3274d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[red_herring] examples: 36\n[red_herring] non-examples: 38\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe9d8d8cfcf422da16bb947311261b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1d3d3172fd4998a5bb75365370ab97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28210d55305e4b43a57daa920068ca96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbfd7d4ca294e278b5ed2cf14277e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nWARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac01e2fcf70497bac8e4f565c5a6f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for red_herring]\n              precision    recall  f1-score   support\n\n           0       1.00      0.60      0.75         5\n           1       0.83      1.00      0.91        10\n\n    accuracy                           0.87        15\n   macro avg       0.92      0.80      0.83        15\nweighted avg       0.89      0.87      0.86        15\n\n✅ Model saved to models/red_herring\n[straw_man] examples: 1\n[straw_man] non-examples: 7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for straw_man]\n              precision    recall  f1-score   support\n\n           0       1.00      0.50      0.67         2\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.50         2\n   macro avg       0.50      0.25      0.33         2\nweighted avg       1.00      0.50      0.67         2\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/straw_man\n[slippery_slope] examples: 1\n[slippery_slope] non-examples: 7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for slippery_slope]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         2\n\n    accuracy                           1.00         2\n   macro avg       1.00      1.00      1.00         2\nweighted avg       1.00      1.00      1.00         2\n\n✅ Model saved to models/slippery_slope\n[attacking] examples: 0\n[attacking] non-examples: 0\n⚠️ Skipping attacking: empty examples or non-examples.\n❌ No data for: attacking\n[ad_hominem] examples: 28\n[ad_hominem] non-examples: 60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for ad_hominem]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        11\n           1       1.00      1.00      1.00         7\n\n    accuracy                           1.00        18\n   macro avg       1.00      1.00      1.00        18\nweighted avg       1.00      1.00      1.00        18\n\n✅ Model saved to models/ad_hominem\n[hasty_generalization] examples: 0\n[hasty_generalization] non-examples: 0\n⚠️ Skipping hasty_generalization: empty examples or non-examples.\n❌ No data for: hasty_generalization\n[ignorance] examples: 42\n[ignorance] non-examples: 37\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for ignorance]\n              precision    recall  f1-score   support\n\n           0       0.71      1.00      0.83         5\n           1       1.00      0.82      0.90        11\n\n    accuracy                           0.88        16\n   macro avg       0.86      0.91      0.87        16\nweighted avg       0.91      0.88      0.88        16\n\n✅ Model saved to models/ignorance\n[hypocrisy] examples: 22\n[hypocrisy] non-examples: 43\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for hypocrisy]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         8\n           1       1.00      1.00      1.00         5\n\n    accuracy                           1.00        13\n   macro avg       1.00      1.00      1.00        13\nweighted avg       1.00      1.00      1.00        13\n\n✅ Model saved to models/hypocrisy\n[stacking_deck] examples: 16\n[stacking_deck] non-examples: 15\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\nEpoch 2/3\nEpoch 3/3\n\n[Evaluation for stacking_deck]\n              precision    recall  f1-score   support\n\n           0       1.00      0.50      0.67         4\n           1       0.60      1.00      0.75         3\n\n    accuracy                           0.71         7\n   macro avg       0.80      0.75      0.71         7\nweighted avg       0.83      0.71      0.70         7\n\n✅ Model saved to models/stacking_deck\n"
     ]
    }
   ],
   "source": [
    "# Safe temporary local storage\n",
    "local_model_dir = \"/local_disk0/tmp/fallacy_models\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "for fallacy_name in fallacies:\n",
    "    examples, non_examples = load_fallacy_data(fallacy_name)\n",
    "    train_fallacy_model(fallacy_name, examples, non_examples)\n",
    "    if not examples or not non_examples:\n",
    "        print(f\"❌ No data for: {fallacy_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3f9816-0522-453c-81e4-499c53cd86a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DO NOT TOUCH BELOW UNRELATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8eb1ab-0b9d-48c1-b93a-fbd18c193ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Safe temporary local storage\n",
    "local_model_dir = \"/local_disk0/tmp/fallacy_models\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "# Copy only trained models into safe path\n",
    "for fallacy in [\"straw_man\", \"red_herring\", \"ad_hominem\"]:  # Add only trained models\n",
    "    src = f\"models/{fallacy}\"\n",
    "    dst = f\"{local_model_dir}/{fallacy}\"\n",
    "    if os.path.exists(src):\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "731d0d40-ee5f-4ab0-ad57-6850cc8cc919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-7930981280555412>, line 66\u001B[0m\n",
       "\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfallacy_ensemble_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FallacyEnsembleModel\n",
       "\u001B[1;32m     64\u001B[0m save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_ensemble_model_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m---> 66\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39msave_model(\n",
       "\u001B[1;32m     67\u001B[0m     path\u001B[38;5;241m=\u001B[39msave_path,\n",
       "\u001B[1;32m     68\u001B[0m     loader_module\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfallacy_ensemble_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,          \u001B[38;5;66;03m# file name WITHOUT .py\u001B[39;00m\n",
       "\u001B[1;32m     69\u001B[0m     code_paths\u001B[38;5;241m=\u001B[39m[clean_code_dir],                     \u001B[38;5;66;03m# the folder that contains the file\u001B[39;00m\n",
       "\u001B[1;32m     70\u001B[0m     python_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFallacyEnsembleModel\u001B[39m\u001B[38;5;124m\"\u001B[39m,             \u001B[38;5;66;03m# the class name\u001B[39;00m\n",
       "\u001B[1;32m     71\u001B[0m     artifacts\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_models\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
       "\u001B[1;32m     72\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    420\u001B[0m disable()\n",
       "\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 422\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m    424\u001B[0m     enable()\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:2979\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, auth_policy, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   2976\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(python_model)\n",
       "\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(python_model, \u001B[38;5;28mstr\u001B[39m):\n",
       "\u001B[0;32m-> 2979\u001B[0m     model_code_path \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_and_get_model_code_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpython_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemp_dir\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2980\u001B[0m     _validate_and_copy_file_to_directory(model_code_path, path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m   2981\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m _load_model_code_path(model_code_path, model_config)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/models/utils.py:1840\u001B[0m, in \u001B[0;36m_validate_and_get_model_code_path\u001B[0;34m(model_code_path, temp_dir)\u001B[0m\n",
       "\u001B[1;32m   1835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (model_code_path\u001B[38;5;241m.\u001B[39mexists() \u001B[38;5;129;01mor\u001B[39;00m _databricks_path_exists(model_code_path)):\n",
       "\u001B[1;32m   1836\u001B[0m     additional_message \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m   1837\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Perhaps you meant \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_code_path\u001B[38;5;241m.\u001B[39msuffix \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1838\u001B[0m     )\n",
       "\u001B[0;32m-> 1840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\n",
       "\u001B[1;32m   1841\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe provided model path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1842\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnsure the file path is valid and try again.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00madditional_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1843\u001B[0m     )\n",
       "\u001B[1;32m   1845\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1846\u001B[0m     \u001B[38;5;66;03m# If `model_code_path` points to a notebook on Databricks, this line throws either\u001B[39;00m\n",
       "\u001B[1;32m   1847\u001B[0m     \u001B[38;5;66;03m# a `FileNotFoundError` or an `OSError`. In this case, try to export the notebook as\u001B[39;00m\n",
       "\u001B[1;32m   1848\u001B[0m     \u001B[38;5;66;03m# a Python file.\u001B[39;00m\n",
       "\u001B[1;32m   1849\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(model_code_path):\n",
       "\n",
       "\u001B[0;31mMlflowException\u001B[0m: The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "MlflowException",
        "evalue": "The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>MlflowException</span>: The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
        "File \u001B[0;32m<command-7930981280555412>, line 66\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfallacy_ensemble_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FallacyEnsembleModel\n\u001B[1;32m     64\u001B[0m save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_ensemble_model_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 66\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39msave_model(\n\u001B[1;32m     67\u001B[0m     path\u001B[38;5;241m=\u001B[39msave_path,\n\u001B[1;32m     68\u001B[0m     loader_module\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfallacy_ensemble_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,          \u001B[38;5;66;03m# file name WITHOUT .py\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     code_paths\u001B[38;5;241m=\u001B[39m[clean_code_dir],                     \u001B[38;5;66;03m# the folder that contains the file\u001B[39;00m\n\u001B[1;32m     70\u001B[0m     python_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFallacyEnsembleModel\u001B[39m\u001B[38;5;124m\"\u001B[39m,             \u001B[38;5;66;03m# the class name\u001B[39;00m\n\u001B[1;32m     71\u001B[0m     artifacts\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_models\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m     72\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    420\u001B[0m disable()\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 422\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    424\u001B[0m     enable()\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:2979\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, auth_policy, **kwargs)\u001B[0m\n\u001B[1;32m   2976\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(python_model)\n\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(python_model, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m-> 2979\u001B[0m     model_code_path \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_and_get_model_code_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpython_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemp_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2980\u001B[0m     _validate_and_copy_file_to_directory(model_code_path, path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2981\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m _load_model_code_path(model_code_path, model_config)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/models/utils.py:1840\u001B[0m, in \u001B[0;36m_validate_and_get_model_code_path\u001B[0;34m(model_code_path, temp_dir)\u001B[0m\n\u001B[1;32m   1835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (model_code_path\u001B[38;5;241m.\u001B[39mexists() \u001B[38;5;129;01mor\u001B[39;00m _databricks_path_exists(model_code_path)):\n\u001B[1;32m   1836\u001B[0m     additional_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1837\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Perhaps you meant \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_code_path\u001B[38;5;241m.\u001B[39msuffix \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1838\u001B[0m     )\n\u001B[0;32m-> 1840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\n\u001B[1;32m   1841\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe provided model path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1842\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnsure the file path is valid and try again.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00madditional_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1843\u001B[0m     )\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1846\u001B[0m     \u001B[38;5;66;03m# If `model_code_path` points to a notebook on Databricks, this line throws either\u001B[39;00m\n\u001B[1;32m   1847\u001B[0m     \u001B[38;5;66;03m# a `FileNotFoundError` or an `OSError`. In this case, try to export the notebook as\u001B[39;00m\n\u001B[1;32m   1848\u001B[0m     \u001B[38;5;66;03m# a Python file.\u001B[39;00m\n\u001B[1;32m   1849\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(model_code_path):\n",
        "\u001B[0;31mMlflowException\u001B[0m: The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Target directory to simulate a proper Python module\n",
    "clean_code_dir = \"/local_disk0/tmp/fallacy_ensemble_module\"\n",
    "os.makedirs(clean_code_dir, exist_ok=True)\n",
    "\n",
    "# Path to the final .py file\n",
    "final_py_path = os.path.join(clean_code_dir, \"fallacy_ensemble_model.py\")\n",
    "\n",
    "# Write the class definition cleanly\n",
    "with open(final_py_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import mlflow.pyfunc\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "class FallacyEnsembleModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        self.fallacy_types = [\n",
    "            \"straw_man\", \"red_herring\", \"ad_hominem\",\n",
    "            \"hasty_generalization\", \"appeal_to_ignorance\",\n",
    "            \"hypocrisy\", \"stacking_deck\"\n",
    "        ]\n",
    "        self.model_dir = context.artifacts[\"model_dir\"]\n",
    "        self.fallacy_models = {}\n",
    "\n",
    "        for fallacy in self.fallacy_types:\n",
    "            model_path = os.path.join(self.model_dir, fallacy)\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"Skipping {fallacy}: model not found at {model_path}\")\n",
    "                continue\n",
    "            try:\n",
    "                model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "                tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "                model.eval()\n",
    "                self.fallacy_models[fallacy] = (tokenizer, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {fallacy}: {e}\")\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        texts = model_input[\"text\"].tolist()\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            fallacy_scores = []\n",
    "            for fallacy, (tokenizer, model) in self.fallacy_models.items():\n",
    "                inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "                    probs = torch.softmax(logits, dim=1)\n",
    "                    fallacy_prob = probs[0][1].item()\n",
    "                fallacy_scores.append((fallacy, fallacy_prob))\n",
    "            fallacy_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            results.append(fallacy_scores)\n",
    "        return results\n",
    "\"\"\")\n",
    "\n",
    "import mlflow.pyfunc\n",
    "import sys\n",
    "sys.path.append(\"/local_disk0/tmp/fallacy_ensemble_module\")\n",
    "from fallacy_ensemble_model import FallacyEnsembleModel\n",
    "\n",
    "save_path = \"/local_disk0/tmp/fallacy_ensemble_model_v1\"\n",
    "\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=save_path,\n",
    "    loader_module=\"fallacy_ensemble_model\",          # file name WITHOUT .py\n",
    "    code_paths=[clean_code_dir],                     # the folder that contains the file\n",
    "    python_model=\"FallacyEnsembleModel\",             # the class name\n",
    "    artifacts={\"model_dir\": \"/local_disk0/tmp/fallacy_models\"}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91db98e1-563e-401c-b176-7a4770cec1cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8027030044030855>, line 14\u001B[0m\n",
       "\u001B[1;32m     11\u001B[0m save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_ensemble_model_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m     12\u001B[0m shutil\u001B[38;5;241m.\u001B[39mrmtree(save_path, ignore_errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\u001B[0;32m---> 14\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39msave_model(\n",
       "\u001B[1;32m     15\u001B[0m     path\u001B[38;5;241m=\u001B[39msave_path,\n",
       "\u001B[1;32m     16\u001B[0m     loader_module\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfallacy_ensemble_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,      \u001B[38;5;66;03m# Matches filename: fallacy_ensemble_model.py\u001B[39;00m\n",
       "\u001B[1;32m     17\u001B[0m     code_paths\u001B[38;5;241m=\u001B[39m[clean_code_dir],                 \u001B[38;5;66;03m# Folder that contains the .py file\u001B[39;00m\n",
       "\u001B[1;32m     18\u001B[0m     python_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFallacyEnsembleModel\u001B[39m\u001B[38;5;124m\"\u001B[39m,         \u001B[38;5;66;03m# Class name in the .py file\u001B[39;00m\n",
       "\u001B[1;32m     19\u001B[0m     artifacts\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_models\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
       "\u001B[1;32m     20\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    420\u001B[0m disable()\n",
       "\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 422\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m    424\u001B[0m     enable()\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:2979\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, auth_policy, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   2976\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(python_model)\n",
       "\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(python_model, \u001B[38;5;28mstr\u001B[39m):\n",
       "\u001B[0;32m-> 2979\u001B[0m     model_code_path \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_and_get_model_code_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpython_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemp_dir\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2980\u001B[0m     _validate_and_copy_file_to_directory(model_code_path, path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m   2981\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m _load_model_code_path(model_code_path, model_config)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/models/utils.py:1840\u001B[0m, in \u001B[0;36m_validate_and_get_model_code_path\u001B[0;34m(model_code_path, temp_dir)\u001B[0m\n",
       "\u001B[1;32m   1835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (model_code_path\u001B[38;5;241m.\u001B[39mexists() \u001B[38;5;129;01mor\u001B[39;00m _databricks_path_exists(model_code_path)):\n",
       "\u001B[1;32m   1836\u001B[0m     additional_message \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m   1837\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Perhaps you meant \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_code_path\u001B[38;5;241m.\u001B[39msuffix \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1838\u001B[0m     )\n",
       "\u001B[0;32m-> 1840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\n",
       "\u001B[1;32m   1841\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe provided model path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1842\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnsure the file path is valid and try again.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00madditional_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1843\u001B[0m     )\n",
       "\u001B[1;32m   1845\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1846\u001B[0m     \u001B[38;5;66;03m# If `model_code_path` points to a notebook on Databricks, this line throws either\u001B[39;00m\n",
       "\u001B[1;32m   1847\u001B[0m     \u001B[38;5;66;03m# a `FileNotFoundError` or an `OSError`. In this case, try to export the notebook as\u001B[39;00m\n",
       "\u001B[1;32m   1848\u001B[0m     \u001B[38;5;66;03m# a Python file.\u001B[39;00m\n",
       "\u001B[1;32m   1849\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(model_code_path):\n",
       "\n",
       "\u001B[0;31mMlflowException\u001B[0m: The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "MlflowException",
        "evalue": "The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>MlflowException</span>: The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
        "File \u001B[0;32m<command-8027030044030855>, line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m save_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_ensemble_model_v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     12\u001B[0m shutil\u001B[38;5;241m.\u001B[39mrmtree(save_path, ignore_errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 14\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39msave_model(\n\u001B[1;32m     15\u001B[0m     path\u001B[38;5;241m=\u001B[39msave_path,\n\u001B[1;32m     16\u001B[0m     loader_module\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfallacy_ensemble_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,      \u001B[38;5;66;03m# Matches filename: fallacy_ensemble_model.py\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     code_paths\u001B[38;5;241m=\u001B[39m[clean_code_dir],                 \u001B[38;5;66;03m# Folder that contains the .py file\u001B[39;00m\n\u001B[1;32m     18\u001B[0m     python_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFallacyEnsembleModel\u001B[39m\u001B[38;5;124m\"\u001B[39m,         \u001B[38;5;66;03m# Class name in the .py file\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     artifacts\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/local_disk0/tmp/fallacy_models\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m     20\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    420\u001B[0m disable()\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 422\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    424\u001B[0m     enable()\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:2979\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, auth_policy, **kwargs)\u001B[0m\n\u001B[1;32m   2976\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(python_model)\n\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(python_model, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m-> 2979\u001B[0m     model_code_path \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_and_get_model_code_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpython_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemp_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2980\u001B[0m     _validate_and_copy_file_to_directory(model_code_path, path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2981\u001B[0m     python_model \u001B[38;5;241m=\u001B[39m _load_model_code_path(model_code_path, model_config)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-b1faa9a0-ee82-4d76-938f-b69d2f75890f/lib/python3.10/site-packages/mlflow/models/utils.py:1840\u001B[0m, in \u001B[0;36m_validate_and_get_model_code_path\u001B[0;34m(model_code_path, temp_dir)\u001B[0m\n\u001B[1;32m   1835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (model_code_path\u001B[38;5;241m.\u001B[39mexists() \u001B[38;5;129;01mor\u001B[39;00m _databricks_path_exists(model_code_path)):\n\u001B[1;32m   1836\u001B[0m     additional_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1837\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Perhaps you meant \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_code_path\u001B[38;5;241m.\u001B[39msuffix \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1838\u001B[0m     )\n\u001B[0;32m-> 1840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\n\u001B[1;32m   1841\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe provided model path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_code_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1842\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnsure the file path is valid and try again.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00madditional_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1843\u001B[0m     )\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1846\u001B[0m     \u001B[38;5;66;03m# If `model_code_path` points to a notebook on Databricks, this line throws either\u001B[39;00m\n\u001B[1;32m   1847\u001B[0m     \u001B[38;5;66;03m# a `FileNotFoundError` or an `OSError`. In this case, try to export the notebook as\u001B[39;00m\n\u001B[1;32m   1848\u001B[0m     \u001B[38;5;66;03m# a Python file.\u001B[39;00m\n\u001B[1;32m   1849\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(model_code_path):\n",
        "\u001B[0;31mMlflowException\u001B[0m: The provided model path '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel' does not exist. Ensure the file path is valid and try again. Perhaps you meant '/Workspace/Users/lramos9658@sdsu.edu/FallacyEnsembleModel.py'?"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Step 1: Create a clean code folder and copy the .py file into it\n",
    "clean_code_dir = \"/local_disk0/tmp/mlflow_fallacy_code\"\n",
    "os.makedirs(clean_code_dir, exist_ok=True)\n",
    "\n",
    "shutil.copy(\"/local_disk0/tmp/fallacy_ensemble_model.py\", f\"{clean_code_dir}/fallacy_ensemble_model.py\")\n",
    "\n",
    "save_path = \"/local_disk0/tmp/fallacy_ensemble_model_v1\"\n",
    "shutil.rmtree(save_path, ignore_errors=True)\n",
    "\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=save_path,\n",
    "    loader_module=\"fallacy_ensemble_model\",      # Matches filename: fallacy_ensemble_model.py\n",
    "    code_paths=[clean_code_dir],                 # Folder that contains the .py file\n",
    "    python_model=\"FallacyEnsembleModel\",         # Class name in the .py file\n",
    "    artifacts={\"model_dir\": \"/local_disk0/tmp/fallacy_models\"}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3526383e-bfab-4ee9-9a3f-8dd99bf96f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Register it in Unity Catalog or default registry\n",
    "registered_model_name = \"fallacy_ensemble_uc\"\n",
    "mlflow.register_model(f\"runs:/{model_artifact_path}\", registered_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "740d9e1a-aca2-4bca-a5ee-7e813dd7f748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b34e5c-083c-470e-9bf7-8282db0e5d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(save_path)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"text\": [\"You're just a student.\"]})\n",
    "predictions = model.predict(df)\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7930981280555425,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Fallacy-Multi-Classifier-Training",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}