{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e1a10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn nltk transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91d8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f8e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/logan.ramos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd67da-808f-4d78-900c-d94d1d4b226a",
   "metadata": {},
   "source": [
    "## Synthetic Data (NOTE: pending professor approval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcb4a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_examples = [\n",
    "    \"You don't know anything about politics, you're just a student.\", \n",
    "    \"That's a ridiculous statement, you're too young to understand.\",\n",
    "    \"Your argument is invalid because you're just a dumb person.\",\n",
    "    \"You don’t have the expertise to be making these kinds of claims.\",\n",
    "    \"What do you know about this? You’re just a student with no real experience.\",\n",
    "    \"You're too young to understand the complexities of this topic.\",\n",
    "    \"You're just an idealist; you don’t know how the world really works.\",\n",
    "    \"You can’t possibly know anything about this; you’ve never worked a real job.\",\n",
    "    \"You're just upset because things aren't going your way.\",\n",
    "    \"You wouldn’t understand; you’re just a part-time worker.\",\n",
    "    \"You're too inexperienced to have a valid opinion on this.\",\n",
    "    \"You’re just repeating what everyone else says; you don’t think for yourself.\",\n",
    "    \"How can you argue with me? You’ve never been in this field.\",\n",
    "    \"What do you know about this? You’ve never even had a leadership role.\",\n",
    "    \"You can't possibly understand, you're just a teenager with no experience.\",\n",
    "    \"You're too emotional to be taken seriously on this matter.\",\n",
    "    \"You can’t contribute to this conversation; you're just a beginner.\",\n",
    "    \"You don’t have enough life experience to understand what's really going on.\",\n",
    "    \"You're just a fan of that person; your opinion is biased.\",\n",
    "    \"You can’t speak with authority because you're not qualified.\",\n",
    "    \"How could you possibly know? You haven’t even been through a real struggle.\",\n",
    "    \"You're too inexperienced to be discussing this seriously.\",\n",
    "    \"You don’t know what you’re talking about; you’ve never been in my shoes.\",\n",
    "    \"You’re just a blogger; your opinion doesn’t count.\",\n",
    "    \"You're too young to see the big picture.\",\n",
    "    \"You’re just a dreamer, not a realist.\",\n",
    "    \"What do you know? You’ve never held a real job.\",\n",
    "    \"You're just saying that because you haven’t lived long enough.\"\n",
    "]\n",
    "\n",
    "synthetic_healthy_arguments = [\n",
    "    \"I understand your point, but I think the data shows something different.\",\n",
    "    \"I see where you're coming from, but let's look at the facts before we make a decision.\",\n",
    "    \"While I respect your perspective, I think we need to consider a wider range of views on this.\",\n",
    "    \"That's an interesting point, but I believe the evidence suggests otherwise.\",\n",
    "    \"I disagree with your conclusion, but let's explore the underlying reasoning together.\",\n",
    "    \"I hear you, but from my experience, I believe the situation is more complex.\",\n",
    "    \"I understand your concerns, and I think it’s important we weigh the pros and cons carefully.\",\n",
    "    \"I appreciate your opinion, but I think it's crucial to also examine the long-term effects.\",\n",
    "    \"You raise a valid point, but we also need to account for other factors in this situation.\",\n",
    "    \"I think it’s important to keep an open mind, as there may be other perspectives to consider.\",\n",
    "    \"I see what you’re saying, but have you thought about the potential downsides?\",\n",
    "    \"I get that you’re frustrated, but let’s try to focus on finding a solution.\",\n",
    "    \"I agree that this is an issue, but I think we should look at all sides before we act.\",\n",
    "    \"I see your concerns, but I think we need to gather more information first.\",\n",
    "    \"That’s a good point, but I think we need to look at this in a broader context.\",\n",
    "    \"I understand your perspective, but the data we have doesn't fully support that view.\",\n",
    "    \"You're right to be concerned, but I think there are other strategies we should also consider.\",\n",
    "    \"I respect your opinion, but let’s take a closer look at the facts before making any conclusions.\",\n",
    "    \"I agree that this could be an issue, but I think we need to address it in a more systematic way.\",\n",
    "    \"I understand your viewpoint, but I think we need to evaluate the situation more thoroughly.\",\n",
    "    \"I appreciate your viewpoint, but let’s also consider the other possible outcomes.\",\n",
    "    \"I see your point, but we need to factor in other variables that might affect the outcome.\",\n",
    "    \"I understand your frustration, but let’s focus on finding a constructive solution.\",\n",
    "    \"I see where you're coming from, but I think it's important to keep the bigger picture in mind.\",\n",
    "    \"I understand the concern, but I think we need to approach this more methodically.\",\n",
    "    \"I respect your perspective, but I think we need to question our assumptions here.\",\n",
    "    \"That’s a valid argument, but we also need to look at the data from multiple angles.\",\n",
    "    \"I agree with your sentiment, but I think it’s essential to test this hypothesis before making a decision.\",\n",
    "    \"I see your point, but I think we should gather more evidence before drawing conclusions.\",\n",
    "    \"I agree that there is an issue, but I think we need to identify the root cause first.\",\n",
    "    \"You make a good argument, but I think we should consider how this will affect the long term.\",\n",
    "    \"I agree with you on some aspects, but we should also factor in other variables.\",\n",
    "    \"I see the merit in your argument, but I believe the situation is more nuanced than that.\",\n",
    "    \"I understand the concern, but perhaps a different approach might be more effective.\",\n",
    "    \"I see your point, but I think it's important to focus on solutions rather than dwelling on the problem.\",\n",
    "    \"I respect your opinion, but I think it’s important to consider the broader implications.\",\n",
    "    \"I agree that change is necessary, but we need to look at sustainable options.\",\n",
    "    \"That’s a good idea, but I think it’s important to balance that with other priorities.\",\n",
    "    \"I understand your frustration, but I think we need to take a step back and look at the bigger picture.\",\n",
    "    \"I appreciate your thoughts, but I believe we need to focus on actionable steps.\",\n",
    "    \"You bring up a valid concern, but let’s also think about the long-term benefits of this decision.\",\n",
    "    \"I see the logic behind your argument, but let’s take a more balanced approach.\",\n",
    "    \"I agree with you on several points, but I think it’s important to consider other options as well.\",\n",
    "    \"That’s a compelling argument, but I think we should explore other alternatives.\",\n",
    "    \"I understand your point of view, but I believe we need to look at the evidence before moving forward.\",\n",
    "    \"I agree that something needs to change, but I think we need a plan that addresses all the underlying issues.\",\n",
    "    \"You have a strong argument, but I think we should be cautious about the potential risks.\",\n",
    "    \"I agree that this is a pressing issue, but let's also consider the potential consequences of this action.\",\n",
    "    \"I understand your reasoning, but I think it’s important to consider the different perspectives involved.\",\n",
    "    \"I respect your opinion, but I believe we need to dig deeper into the facts before making a final decision.\"\n",
    "] \n",
    "synthetic_non_arguments = [\n",
    "    \"The weather today is very nice, with clear skies and a mild breeze.\",\n",
    "    \"I enjoy listening to music in my free time.\",\n",
    "    \"There’s a coffee shop near my house that I go to every weekend.\",\n",
    "    \"I recently started reading a new book that seems really interesting.\",\n",
    "    \"My favorite season of the year is autumn because of the colors of the leaves.\",\n",
    "    \"I think I'll have pasta for dinner tonight.\",\n",
    "    \"I like to go for walks in the park to relax.\",\n",
    "    \"I noticed that the flowers in my garden are blooming beautifully this spring.\",\n",
    "    \"I love watching documentaries on wildlife.\",\n",
    "    \"My friend just adopted a dog, and it’s so cute.\"\n",
    "] \n",
    "synthetic_non_examples = synthetic_non_arguments + synthetic_healthy_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5669baee-632b-4e35-a16c-a8cc6d58ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels = [1] * len(synthetic_examples)\n",
    "negative_labels = [0] * len(synthetic_non_examples)\n",
    "labels = [*positive_labels, *negative_labels]\n",
    "texts = [*synthetic_examples, *synthetic_non_examples]\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e87c8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def encode_texts(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    return tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "train_encodings = encode_texts(X_train)\n",
    "test_encodings = encode_texts(X_test)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_labels = torch.tensor(y_test)\n",
    "train_dataset = TensorDataset(train_encodings.input_ids, train_encodings.attention_mask, train_labels)\n",
    "test_dataset = TensorDataset(test_encodings.input_ids, test_encodings.attention_mask, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c56b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 completed.\n",
      "Epoch 2/3 completed.\n",
      "Epoch 3/3 completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('ad_hominem_model/tokenizer_config.json',\n",
       " 'ad_hominem_model/special_tokens_map.json',\n",
       " 'ad_hominem_model/vocab.txt',\n",
       " 'ad_hominem_model/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "model.train()\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} completed.\")\n",
    "model.save_pretrained(\"ad_hominem_model\")\n",
    "tokenizer.save_pretrained(\"ad_hominem_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9c23d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d9a57c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_ad_hominem(text):\n",
    "    encoding = encode_texts([text])\n",
    "    input_ids = encoding.input_ids\n",
    "    attention_mask = encoding.attention_mask\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"Ad Hominem\" if prediction == 1 else \"good\"\n",
    "    \n",
    "predict_ad_hominem(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e246f1d7-7f4e-47cd-8ba8-534150dcf71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fd015-4f4a-4472-8f5a-a136d0edf637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
